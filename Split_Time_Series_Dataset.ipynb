{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Split Time-Series Dataset.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOM14iQwqcJlRoc0OGypL9h"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://tomerkatzav.medium.com/split-time-series-dataset-826b7dc39cd9)"
      ],
      "metadata": {
        "id": "RypnkJZzmsqM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hhmc3qZcjbGA"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris = load_iris()"
      ],
      "metadata": {
        "id": "viaH0GJVm29O"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = iris.data, iris.target\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "CH2B61LMm4Hu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "\n",
        "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4], [1, 2], [3, 4]])\n",
        "y = np.array([1, 2, 3, 4, 5, 6])\n",
        "tscv = TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None)\n",
        "for train_index, test_index in tscv.split(X):\n",
        "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAgyklKTm7Et",
        "outputId": "3f66c518-8411-4f65-9740-8cc91d207305"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN: [0] TEST: [1]\n",
            "TRAIN: [0 1] TEST: [2]\n",
            "TRAIN: [0 1 2] TEST: [3]\n",
            "TRAIN: [0 1 2 3] TEST: [4]\n",
            "TRAIN: [0 1 2 3 4] TEST: [5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# predefine the variables\n",
        "n_splits = 5  # Number of splits\n",
        "model = RandomForestRegressor()  # I used random forest as my model\n",
        "# Add the parameter to grid serach on - this is just an example\n",
        "grid_params = {'n_estimators': [int(x) for x in np.linspace(200, 1000, 3)],\n",
        "              'max_depth': [int(x) for x in np.linspace(5, 55, 11)],\n",
        "              'max_features': ['auto', 'sqrt', 'log2'],\n",
        "              'random_state': [42]\n",
        "              }\n",
        "refit = True  # Refit an estimator using the best found parameters on the whole dataset\n",
        "scoring = 'neg_mean_squared_error'  # Strategy to evaluate the performance of the cross-validated model on the test set\n",
        "n_jobs = -1  # Number of jobs to run in parallel\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=grid_params, refit=refit,\n",
        "                           scoring=scoring, cv=tscv, n_jobs=n_jobs).fit(X, y)\n",
        "print(f'Model: {model} best params are: {grid_search.best_params_}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1_qEu1bot7R",
        "outputId": "d6a77313-fdf3-48f8-c4da-edb47eadf8e6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: RandomForestRegressor() best params are: {'max_depth': 5, 'max_features': 'auto', 'n_estimators': 1000, 'random_state': 42}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
        "\n",
        "model = RandomForestRegressor()\n",
        "grid_params = {'n_estimators': [int(x) for x in np.linspace(200, 1000, 3)],\n",
        "               'max_depth': [int(x) for x in np.linspace(5, 55, 11)],\n",
        "               'max_features': ['auto', 'sqrt', 'log2'],\n",
        "               'random_state': [42]\n",
        "               }\n",
        "refit = True\n",
        "scoring = 'neg_mean_squared_error'\n",
        "n_jobs = -1\n",
        "validation_size = 24\n",
        "X.reset_index(inplace=True)\n",
        "X.sort_values('date', inplace=True)\n",
        "train_dates = pd.to_datetime(X['date'].unique()).sort_values()\n",
        "\n",
        "val_dates = train_dates[-validation_size:]\n",
        "\n",
        "n_test_obs = X['date'].isin(train_dates).sum()\n",
        "n_valid_obs = X['date'].isin(val_dates).sum()\n",
        "\n",
        "test_fold_encoding = list(np.concatenate([np.ones(n_test_obs - n_valid_obs), np.zeros(n_valid_obs)]))\n",
        "\n",
        "cv = [[c for c in PredefinedSplit(test_fold=test_fold_encoding).split()][0]]\n",
        "\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=grid_params, refit=refit,\n",
        "                           scoring=scoring, cv=cv, n_jobs=n_jobs).fit(X, y)\n",
        "print(f'Model: {model} best params are: {grid_search.best_params_}')\n"
      ],
      "metadata": {
        "id": "cyiAPa7CrtHt"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}