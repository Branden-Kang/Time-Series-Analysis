{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Forecasting Oil Production Rate (Univariate Time Series).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO4a8jxHR2FjgWWTQWziLs4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://rezayazdanfar.medium.com/forecasting-oil-production-rate-univariate-time-series-b12801be899b)"
      ],
      "metadata": {
        "id": "akt5Ci3j_KgF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cqb1Pw2T-Ff3"
      },
      "outputs": [],
      "source": [
        "# create a differenced series\n",
        "def difference(dataset, interval=1):\n",
        "    diff = list()\n",
        "    for i in range(interval, len(dataset)):\n",
        "        value = dataset[i] - dataset[i - interval]\n",
        "        diff.append(value)\n",
        "    return Series(diff)\n",
        "\n",
        "# invert differenced value\n",
        "def inverse_difference(history, yhat, interval=1):\n",
        "    return yhat + history[-interval]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# scale train and test data to [-1, 1]\n",
        "def scale(train, test):\n",
        "    # fit scaler\n",
        "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "    scaler = scaler.fit(train)\n",
        "    # transform train\n",
        "    train = train.reshape(train.shape[0], train.shape[1])\n",
        "    train_scaled = scaler.transform(train)\n",
        "    # transform test\n",
        "    test = test.reshape(test.shape[0], test.shape[1])\n",
        "    test_scaled = scaler.transform(test)\n",
        "    return scaler, train_scaled, test_scaled\n",
        "\n",
        "# inverse scaling for a forecasted value\n",
        "def invert_scale(scaler, X, value):\n",
        "    new_row = [x for x in X] + [value]\n",
        "    array = np.array(new_row)\n",
        "    array = array.reshape(1, len(array))\n",
        "    inverted = scaler.inverse_transform(array)\n",
        "    return inverted[0, -1]"
      ],
      "metadata": {
        "id": "ps42VUF1_Qf3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert an array of values into a dataset matrix\n",
        "def create_dataset(dataset, look_back=1):\n",
        "    dataset = np.insert(dataset,[0]*look_back,0)    \n",
        "    dataX, dataY = [], []\n",
        "    for i in range(len(dataset)-look_back):\n",
        "        a = dataset[i:(i+look_back)]\n",
        "        dataX.append(a)\n",
        "        dataY.append(dataset[i + look_back])\n",
        "    dataY= np.array(dataY)        \n",
        "    dataY = np.reshape(dataY,(dataY.shape[0],1))\n",
        "    dataset = np.concatenate((dataX,dataY),axis=1)  \n",
        "    return dataset"
      ],
      "metadata": {
        "id": "GAmnlVpf_Tjl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  RMSPE\n",
        "def RMSPE(x,y):\n",
        "    result=0\n",
        "    for i in range(len(x)):\n",
        "        result += ((x[i]-y[i])/x[i])**2\n",
        "    result /= len(x)\n",
        "    result = sqrt(result)\n",
        "    result *= 100\n",
        "    return result\n",
        "\n",
        "#  MAPE\n",
        "def MAPE(x,y):\n",
        "    result=0\n",
        "    for i in range(len(x)):\n",
        "        result += abs((x[i]-y[i])/x[i])\n",
        "    result /= len(x)\n",
        "    result *= 100\n",
        "    return result"
      ],
      "metadata": {
        "id": "3sGGy9Mb_VeD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit an LSTM network to training data\n",
        "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
        "    X, y = train[:, 0:-1], train[:, -1]\n",
        "    X = X.reshape(X.shape[0], X.shape[1],1 )\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(neurons[0], batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True,return_sequences=True))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(LSTM(neurons[1], batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True,return_sequences=True))\n",
        "    model.add(Dropout(0.5))\n",
        "    \n",
        "    model.add(Dense(3,'relu'))\n",
        "   \n",
        "    model.add(Dense(1))\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "    for i in range(nb_epoch):\n",
        "        print('epoch:',i+1)\n",
        "        model.fit(X, y, epochs=10, batch_size=batch_size, verbose=1, shuffle=False)\n",
        "        model.reset_states()\n",
        "    return model\n",
        "    \n",
        "# make a one-step forecast\n",
        "def forecast_lstm(model, batch_size, X):\n",
        "    X = X.reshape(1, len(X), 1)\n",
        "    yhat = model.predict(X, batch_size=batch_size)\n",
        "    return yhat[0,0]"
      ],
      "metadata": {
        "id": "1QD6jNXm_XX7"
      },
      "execution_count": 5,
      "outputs": []
    }
  ]
}