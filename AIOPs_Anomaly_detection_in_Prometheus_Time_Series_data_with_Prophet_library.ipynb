{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AIOPs: Anomaly detection in Prometheus Time Series data with Prophet library.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN++tbZoRksqO9+DX2/9mzS"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://medium.com/data-science-engineering/using-time-series-forecasting-library-prophet-for-anomaly-detection-55fe36588f2f)"
      ],
      "metadata": {
        "id": "f6fcSfut6vHs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wl-I-E2Y6rbs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from prophet import Prophet\n",
        "from prophet.plot import add_changepoints_to_plot\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "df = pd.read_csv(\"History of Save failures-data-2022-04-02 11_43_03.csv\")\n",
        "print(\"Input data\")\n",
        "print(df.head)\n",
        "df.columns=[\"ds\",\"y\"]\n",
        "# If you need to convert data\n",
        "#df[\"ds\"] =  pd.to_datetime(df[\"ds\"],utc=False,unit='s')\n",
        "#df['ds'] = pd.to_datetime(df.ds)\n",
        "print(df.head)\n",
        "\n",
        "m = Prophet(changepoint_prior_scale=0.05,changepoint_range=1,interval_width=.95)\n",
        "m.fit(df)\n",
        "\n",
        "# we are not concerned about predicting here, rather just fitting the data\n",
        "future = m.make_future_dataframe(periods =2,freq='2h') \n",
        "print(\" -- make_future_dataframe-- \")\n",
        "print(future.tail())\n",
        "\n",
        "\n",
        "forecast = m.predict(future)\n",
        "print(\" -- model predict-- \")\n",
        "print(forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail())\n",
        "\n",
        "fig = m.plot(forecast)\n",
        "fig.savefig('forecastwiki.png')\n",
        "\n",
        "#Lets identify the points that are over the threshold\n",
        "\n",
        " # find the dataframes having same indices\n",
        "forecast_truncated_index =forecast.index.intersection(df.index)\n",
        "forecast_truncated = forecast.loc[forecast_truncated_index]\n",
        "print(forecast_truncated.shape[0],df.shape[0])\n",
        "\n",
        "# Identify the thresholds \n",
        "#indices =m.history[m.history['y'] > forecast_truncated['yhat_upper'] + buffer].index\n",
        "\n",
        "# Identify the thresholds with some buffer\n",
        "buffer = np.max( forecast_truncated['yhat_upper'])\n",
        "print(\"Buffer=\",buffer)\n",
        "indices =m.history[m.history['y'] > buffer].index\n",
        "\n",
        "# Get those points that have crossed the threshold\n",
        "thresholded_df  = m.history.iloc[indices] # ------> This has the thresholded values and more important timestamp\n",
        "\n",
        "figsize=(10, 6)\n",
        "fig = plt.figure(facecolor='w', figsize=figsize)\n",
        "ax = fig.add_subplot(111)\n",
        "fig = m.plot(forecast,ax=ax)\n",
        "\n",
        "# plot the threhsolded points as red\n",
        "ax.plot(thresholded_df['ds'].dt.to_pydatetime(), thresholded_df['y'], 'r.',\n",
        "        label='Thresholded data points')\n",
        "fig.savefig('forecastwiki_thresholded.png')"
      ]
    }
  ]
}