{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/9w9t721Dgluwg4qMPM1H"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://medium.com/@Rohan_Dutt/10-forecasting-models-used-for-revenue-sales-and-demand-prediction-in-industry-162be7ef02ea)"
      ],
      "metadata": {
        "id": "P6WnxY5Gt2J1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Ensemble Forecasting"
      ],
      "metadata": {
        "id": "vFYFC3Tjt58o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "itj8HmkttfzH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Example: forecasts from three models\n",
        "data = pd.read_csv(\"model_forecasts.csv\")\n",
        "# Columns: 'ARIMA', 'Prophet', 'XGBoost', 'Actual'\n",
        "\n",
        "# Simple average ensemble\n",
        "data['Ensemble_avg'] = data[['ARIMA','Prophet','XGBoost']].mean(axis=1)\n",
        "\n",
        "# Stacked regression ensemble\n",
        "X = data[['ARIMA','Prophet','XGBoost']]\n",
        "y = data['Actual']\n",
        "stack_model = LinearRegression()\n",
        "stack_model.fit(X, y)\n",
        "data['Ensemble_stacked'] = stack_model.predict(X)\n",
        "\n",
        "print(data[['Actual','Ensemble_avg','Ensemble_stacked']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Causal Impact (Bayesian Structural Time-Series)"
      ],
      "metadata": {
        "id": "GqCj5uKVuCIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from causalimpact import CausalImpact\n",
        "\n",
        "# Example: daily sales before & after campaign\n",
        "data = pd.read_csv(\"sales_campaign.csv\", parse_dates=[\"Date\"], index_col=\"Date\")\n",
        "pre_period = [0, 29]  # first 30 days\n",
        "post_period = [30, 59]  # next 30 days after campaign\n",
        "\n",
        "ci = CausalImpact(data, pre_period, post_period)\n",
        "print(ci.summary())\n",
        "ci.plot()"
      ],
      "metadata": {
        "id": "qKg1xxRRt7xa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Dynamic Regression"
      ],
      "metadata": {
        "id": "A_3I7-3puIYc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Example: Daily sales and temperature data\n",
        "data = pd.read_csv(\"sales_weather.csv\", parse_dates=[\"Date\"], index_col=\"Date\")\n",
        "y = data[\"Sales\"]\n",
        "X = data[[\"Temperature\", \"Promotion\"]]\n",
        "\n",
        "# Add intercept\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Fit dynamic regression (ARIMAX)\n",
        "model = sm.tsa.SARIMAX(y, exog=X, order=(1,0,0))\n",
        "fit = model.fit()\n",
        "print(fit.summary())\n",
        "\n",
        "# Forecast next 7 days with future predictors\n",
        "future_X = pd.DataFrame({\n",
        "    \"const\": 1,\n",
        "    \"Temperature\": [22, 23, 21, 20, 22, 24, 23],\n",
        "    \"Promotion\": [0,1,0,0,1,0,1]\n",
        "})\n",
        "forecast = fit.get_forecast(steps=7, exog=future_X)\n",
        "print(forecast.predicted_mean)"
      ],
      "metadata": {
        "id": "pP-ZxRxUuFt5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Bass Diffusion Model"
      ],
      "metadata": {
        "id": "OiCs86THuRES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.optimize import curve_fit\n",
        "\n",
        "# Bass model function\n",
        "def bass_model(t, p, q, m):\n",
        "    return m * ((1 - np.exp(-(p+q)*t)) / (1 + (q/p)*np.exp(-(p+q)*t)))\n",
        "\n",
        "# Example: hypothetical adoption data\n",
        "t = np.arange(1, 21)  # 20 weeks\n",
        "adopters = np.array([2, 5, 12, 20, 35, 50, 70, 95, 120, 150, 180, 210, 240, 270, 295, 320, 340, 355, 370, 380])\n",
        "\n",
        "# Fit Bass model\n",
        "params, _ = curve_fit(bass_model, t, adopters, bounds=(0, [1,1,1000]))\n",
        "p, q, m = params\n",
        "print(f\"p={p:.3f}, q={q:.3f}, total market={m:.0f}\")\n",
        "\n",
        "# Forecast next 10 weeks\n",
        "t_future = np.arange(21, 31)\n",
        "forecast = bass_model(t_future, p, q, m)\n",
        "\n",
        "plt.plot(t, adopters, 'o', label='Observed')\n",
        "plt.plot(np.concatenate([t, t_future]), np.concatenate([adopters, forecast]), '-', label='Bass Forecast')\n",
        "plt.xlabel(\"Weeks\")\n",
        "plt.ylabel(\"Cumulative Adopters\")\n",
        "plt.title(\"Bass Diffusion Forecast\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WM4wKu4xuM-a"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Market Mix Modeling (MMM)"
      ],
      "metadata": {
        "id": "gontoJ01uXus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Example: Monthly spend & sales\n",
        "data = pd.read_csv(\"marketing_sales.csv\")\n",
        "X = data[[\"TV\", \"Google_Ads\", \"Promo\"]]\n",
        "y = data[\"Sales\"]\n",
        "\n",
        "# Add intercept\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Fit linear regression\n",
        "model = sm.OLS(y, X).fit()\n",
        "print(model.summary())\n",
        "\n",
        "# Bayesian update (simplified)\n",
        "from pydataset import data as pydataset_data\n",
        "import pymc as pm\n",
        "\n",
        "with pm.Model() as bayes_model:\n",
        "    alpha = pm.Normal(\"alpha\", mu=0, sigma=10)\n",
        "    betas = pm.Normal(\"betas\", mu=0, sigma=5, shape=X.shape[1]-1)\n",
        "    sigma = pm.HalfNormal(\"sigma\", sigma=10)\n",
        "    mu = alpha + pm.math.dot(X.iloc[:,1:], betas)\n",
        "    y_obs = pm.Normal(\"y_obs\", mu=mu, sigma=sigma, observed=y)\n",
        "    trace = pm.sample(1000, tune=1000, cores=1, progressbar=False)\n",
        "\n",
        "pm.summary(trace, var_names=[\"alpha\",\"betas\",\"sigma\"])"
      ],
      "metadata": {
        "id": "7imwIFOIuTRt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Monte Carlo Simulation"
      ],
      "metadata": {
        "id": "IUJpq1_BuddW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Example: simulate 12 months of revenue forecasts\n",
        "np.random.seed(42)\n",
        "mean_revenue = 50000      # base monthly revenue\n",
        "std_dev = 8000            # volatility\n",
        "n_simulations = 10000\n",
        "\n",
        "# Run simulations\n",
        "simulated_totals = np.random.normal(mean_revenue, std_dev, n_simulations)\n",
        "\n",
        "# Probability of exceeding target\n",
        "target = 55000\n",
        "prob = np.mean(simulated_totals > target)\n",
        "print(f\"Probability revenue exceeds ${target:,}: {prob:.2%}\")\n",
        "\n",
        "# Visualize distribution\n",
        "plt.hist(simulated_totals, bins=50, alpha=0.7)\n",
        "plt.axvline(target, color='red', linestyle='--')\n",
        "plt.title(\"Monte Carlo Revenue Distribution\")\n",
        "plt.xlabel(\"Simulated Monthly Revenue\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vU_uvPRiuWKx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Prophet by Facebook\n",
        "Prophet simplifies time-series forecasting with automatic seasonality detection and intuitive parameters."
      ],
      "metadata": {
        "id": "yJ3F5K0jujRW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. XGBoost + LSTMs (Machine Learning Technique)"
      ],
      "metadata": {
        "id": "L9OCfJERuoV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Example: price, weather, and past sales data\n",
        "data = pd.read_csv(\"sales_with_weather.csv\")\n",
        "X = data[[\"Price\", \"Temperature\", \"Promotion\"]]\n",
        "y = data[\"Sales\"]\n",
        "\n",
        "# Step 1: XGBoost for external features\n",
        "xgb_model = xgb.XGBRegressor(n_estimators=200, learning_rate=0.05)\n",
        "xgb_model.fit(X, y)\n",
        "\n",
        "# Step 2: LSTM for time-based patterns\n",
        "seq = y.values[-100:].reshape(1, 100, 1)  # last 100 days\n",
        "model = Sequential([\n",
        "    LSTM(64, activation='relu', input_shape=(100, 1)),\n",
        "    Dense(1)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.fit(seq, y.values[-100:].reshape(1, 1), epochs=20, verbose=0)\n",
        "\n",
        "# Forecast next step\n",
        "future = model.predict(seq)\n",
        "print(f\"Next predicted sales: {future.flatten()[0]:.2f}\")"
      ],
      "metadata": {
        "id": "rmS64hrmuhil"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Exponential Smoothing (ETS)"
      ],
      "metadata": {
        "id": "E8i2bls-uww1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
        "\n",
        "# Example: Daily sales data\n",
        "data = pd.read_csv(\"daily_sales.csv\", parse_dates=[\"Date\"], index_col=\"Date\")\n",
        "\n",
        "# Fit ETS model with trend and seasonality\n",
        "model = ExponentialSmoothing(\n",
        "    data[\"Sales\"],\n",
        "    trend=\"add\",\n",
        "    seasonal=\"add\",\n",
        "    seasonal_periods=7  # weekly seasonality\n",
        ")\n",
        "fit = model.fit()\n",
        "\n",
        "# Forecast next 14 days\n",
        "forecast = fit.forecast(steps=14)\n",
        "print(forecast)"
      ],
      "metadata": {
        "id": "GcGc1PNcuurp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Time Series Analysis (ARIMA)"
      ],
      "metadata": {
        "id": "eCZwkJbeu1Hx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from pmdarima import auto_arima\n",
        "\n",
        "# Example: Monthly retail sales data\n",
        "data = pd.read_csv(\"retail_sales.csv\", parse_dates=[\"Month\"], index_col=\"Month\")\n",
        "\n",
        "# Auto-select best (p,d,q) parameters\n",
        "auto_model = auto_arima(data[\"Sales\"], seasonal=False, trace=True)\n",
        "print(auto_model.summary())\n",
        "\n",
        "# Fit final ARIMA model\n",
        "model = ARIMA(data[\"Sales\"], order=auto_model.order)\n",
        "fit = model.fit()\n",
        "\n",
        "# Forecast next 6 months\n",
        "forecast = fit.forecast(steps=6)\n",
        "print(forecast)"
      ],
      "metadata": {
        "id": "l6itxSAxuzMa"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}